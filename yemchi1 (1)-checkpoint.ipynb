{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Fake News Classifiers\n",
    "\n",
    "I wrote a longer explanation of the methodology and approach for detecting fake news using scikit-learn on DataCamp (and you can [find the notebook on my GitHub](https://github.com/kjam/random_hackery/blob/master/Attempting%20to%20detect%20fake%20news.ipynb)). I would start there if you are curious as to why I chose the data, what I learned about the models and so forth.\n",
    "\n",
    "In this notebook, I wanted to compare some of the features learned by each classifier to see if there was overlap or patterns in the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 9: expected 3 fields, saw 9\\nSkipping line 11: expected 3 fields, saw 9\\nSkipping line 12: expected 3 fields, saw 4\\nSkipping line 13: expected 3 fields, saw 11\\nSkipping line 16: expected 3 fields, saw 6\\nSkipping line 17: expected 3 fields, saw 4\\nSkipping line 19: expected 3 fields, saw 10\\nSkipping line 20: expected 3 fields, saw 4\\nSkipping line 22: expected 3 fields, saw 11\\nSkipping line 23: expected 3 fields, saw 5\\nSkipping line 25: expected 3 fields, saw 10\\nSkipping line 26: expected 3 fields, saw 7\\nSkipping line 29: expected 3 fields, saw 4\\nSkipping line 30: expected 3 fields, saw 8\\nSkipping line 31: expected 3 fields, saw 4\\nSkipping line 34: expected 3 fields, saw 4\\nSkipping line 35: expected 3 fields, saw 7\\nSkipping line 40: expected 3 fields, saw 5\\nSkipping line 42: expected 3 fields, saw 8\\nSkipping line 44: expected 3 fields, saw 7\\nSkipping line 45: expected 3 fields, saw 8\\nSkipping line 47: expected 3 fields, saw 9\\nSkipping line 49: expected 3 fields, saw 5\\nSkipping line 50: expected 3 fields, saw 4\\nSkipping line 51: expected 3 fields, saw 4\\nSkipping line 52: expected 3 fields, saw 13\\nSkipping line 55: expected 3 fields, saw 7\\nSkipping line 56: expected 3 fields, saw 6\\nSkipping line 58: expected 3 fields, saw 4\\nSkipping line 60: expected 3 fields, saw 4\\nSkipping line 62: expected 3 fields, saw 6\\nSkipping line 66: expected 3 fields, saw 5\\nSkipping line 68: expected 3 fields, saw 4\\nSkipping line 69: expected 3 fields, saw 5\\nSkipping line 71: expected 3 fields, saw 6\\nSkipping line 72: expected 3 fields, saw 8\\nSkipping line 73: expected 3 fields, saw 4\\nSkipping line 81: expected 3 fields, saw 10\\nSkipping line 83: expected 3 fields, saw 4\\nSkipping line 96: expected 3 fields, saw 4\\nSkipping line 98: expected 3 fields, saw 4\\nSkipping line 99: expected 3 fields, saw 11\\nSkipping line 101: expected 3 fields, saw 4\\nSkipping line 102: expected 3 fields, saw 6\\nSkipping line 103: expected 3 fields, saw 7\\nSkipping line 107: expected 3 fields, saw 5\\nSkipping line 149: expected 3 fields, saw 4\\n'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'TestAndTrain123.csv',encoding='latin-1', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models\n",
    "\n",
    "Now I have my vectors and I can create my different classifiers. In my post I noted that there is definitely noise in the dataset, so we should expect to see that reflected in our features. Normally, I would spend some time cleaning the data, but this was a small proof of concept and investigation. I hoped merely that at least one model would be able to correct for the noise.\n",
    "\n",
    "I will compare the following models (and training data):\n",
    "\n",
    "- multinomialNB with counts (`sgd_count_clf`)\n",
    "- multinomialNB with tf-idf (`mn_tfidf_clf`)\n",
    "- passive aggressive with tf-idf (`pa_tfidf_clf`)\n",
    "- linear svc with tf-idf (`svc_tfidf_clf`)\n",
    "- linear sgd with tf-idf (`sgd_tfidf_clf`)\n",
    "\n",
    "For speed and clarity, I am primarily not doing parameter tuning, although this could be added as a step (perhaps in a scikit-learn Pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_count_clf = MultinomialNB(alpha=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.588\n"
     ]
    }
   ],
   "source": [
    "mn_count_clf.fit(count_train, y_train)\n",
    "pred = mn_count_clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_tfidf_clf = MultinomialNB(alpha=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.618\n"
     ]
    }
   ],
   "source": [
    "mn_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = mn_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_tfidf_clf = PassiveAggressiveClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.588\n"
     ]
    }
   ],
   "source": [
    "pa_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = pa_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tfidf_clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.529\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = svc_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tfidf_clf = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.588\n"
     ]
    }
   ],
   "source": [
    "sgd_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = sgd_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tfidf_clf.decision_function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_count_clf.predict_proba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17d0d03bc18>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0).clf()\n",
    "\n",
    "for model, name in [ (mn_count_clf, 'multinomial nb count'),\n",
    "                     (mn_tfidf_clf, 'multinomial nb tfidf'),\n",
    "                     (pa_tfidf_clf, 'passive aggressive'),\n",
    "                     (svc_tfidf_clf, 'svc'),\n",
    "                     (sgd_tfidf_clf, 'sgd')]:\n",
    "    if 'count' in name:\n",
    "        pred = model.predict_proba(count_test)[:,1]\n",
    "    elif 'multinomial' in name:\n",
    "        pred = model.predict_proba(tfidf_test)[:,1]\n",
    "    else: \n",
    "        pred = model.decision_function(tfidf_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test.values, pred, pos_label='REAL')\n",
    "    plt.plot(fpr,tpr,label=\"{}\".format(name))\n",
    "\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introspecting models\n",
    "\n",
    "My main goal for this notebook is not to compare accuracy, but to compare features learned. To do so, we can use the method shown in this [very useful StackOverflow answer](https://stackoverflow.com/a/26980472) to show significant features in a binary classifier. I will use a modified version to return top features for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FAKE': [(-2.716222336335082, 'chronic'),\n",
       "  (-2.5664779346399884, 'taxes'),\n",
       "  (-2.3452288177299554, 'second'),\n",
       "  (-2.2333710510475817, 'good'),\n",
       "  (-2.1998525821491586, 'man'),\n",
       "  (-1.9065191262702519, 'accepted'),\n",
       "  (-0.9532595631351259, 'acceptance'),\n",
       "  (-0.9532595631351259, 'accepting'),\n",
       "  (-0.9532595631351259, 'applauded'),\n",
       "  (-0.9532595631351259, 'foster')],\n",
       " 'REAL': [(0.9017821600417825, 'blow'),\n",
       "  (0.9017821600417825, 'case'),\n",
       "  (0.9017821600417825, 'creating'),\n",
       "  (0.9017821600417825, 'creation'),\n",
       "  (0.9017821600417825, 'dealt'),\n",
       "  (0.9017821600417825, 'happened'),\n",
       "  (0.9017821600417825, 'harmed'),\n",
       "  (0.9017821600417825, 'monopolies'),\n",
       "  (0.9767987058012866, 'block'),\n",
       "  (2.351396045837897, 'immigration')]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=100):\n",
    "    \"\"\"\n",
    "    See: https://stackoverflow.com/a/26980472\n",
    "    \n",
    "    Identify most important features if given a vectorizer and binary classifier. Set n to the number\n",
    "    of weighted features you would like to show. (Note: current implementation merely prints and does not \n",
    "    return top classes.)\n",
    "    \n",
    "    Modified by @kjam to support a dict return.\n",
    "    \"\"\"\n",
    "\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    return {class_labels[0]: topn_class1,\n",
    "            class_labels[1]: topn_class2\n",
    "    }\n",
    "\n",
    "\n",
    "most_informative_feature_for_binary_classification(tfidf_vectorizer, pa_tfidf_clf, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [(mn_count_clf, count_vectorizer),\n",
    "               (mn_tfidf_clf, tfidf_vectorizer),\n",
    "               (pa_tfidf_clf, tfidf_vectorizer),\n",
    "               (svc_tfidf_clf, tfidf_vectorizer),\n",
    "               (sgd_tfidf_clf, tfidf_vectorizer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for clf, vct in classifiers:\n",
    "    results[clf] = most_informative_feature_for_binary_classification(vct, clf, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True): {'FAKE': [(-9.946977983610656,\n",
       "    '100th'),\n",
       "   (-9.946977983610656, '12th'),\n",
       "   (-9.946977983610656, '16'),\n",
       "   (-9.946977983610656, '1950s'),\n",
       "   (-9.946977983610656, '1960s'),\n",
       "   (-9.946977983610656, '1978'),\n",
       "   (-9.946977983610656, '200'),\n",
       "   (-9.946977983610656, '2007'),\n",
       "   (-9.946977983610656, '2011'),\n",
       "   (-9.946977983610656, '20m')],\n",
       "  'REAL': [(-5.684298106569341, 'president'),\n",
       "   (-5.684298106569341, 'trump'),\n",
       "   (-5.552528828938217, 'commission'),\n",
       "   (-5.552528828938217, 'exchange'),\n",
       "   (-5.552528828938217, 'stock'),\n",
       "   (-5.436118477093807, 'company'),\n",
       "   (-5.436118477093807, 'deal'),\n",
       "   (-5.436118477093807, 'firm'),\n",
       "   (-5.331857466769397, 'eu'),\n",
       "   (-4.273654716439164, 'said')]},\n",
       " MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True): {'FAKE': [(-8.339818201229322,\n",
       "    '100th'),\n",
       "   (-8.339818201229322, '12th'),\n",
       "   (-8.339818201229322, '16'),\n",
       "   (-8.339818201229322, '1950s'),\n",
       "   (-8.339818201229322, '1960s'),\n",
       "   (-8.339818201229322, '1978'),\n",
       "   (-8.339818201229322, '200'),\n",
       "   (-8.339818201229322, '2007'),\n",
       "   (-8.339818201229322, '2011'),\n",
       "   (-8.339818201229322, '20m')],\n",
       "  'REAL': [(-6.418573925454975, 'billion'),\n",
       "   (-6.406026340281887, 'exchange'),\n",
       "   (-6.403966111501596, 'deal'),\n",
       "   (-6.387730227468486, 'firm'),\n",
       "   (-6.362406779412281, 'stock'),\n",
       "   (-6.359340488297463, 'china'),\n",
       "   (-6.340465153678301, 'lse'),\n",
       "   (-6.2815622521501595, 'company'),\n",
       "   (-6.272961041912019, 'eu'),\n",
       "   (-5.742475991864196, 'said')]},\n",
       " PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                             early_stopping=False, fit_intercept=True,\n",
       "                             loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
       "                             n_jobs=None, random_state=None, shuffle=True,\n",
       "                             tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False): {'FAKE': [(-2.716222336335082,\n",
       "    'chronic'),\n",
       "   (-2.5664779346399884, 'taxes'),\n",
       "   (-2.3452288177299554, 'second'),\n",
       "   (-2.2333710510475817, 'good'),\n",
       "   (-2.1998525821491586, 'man'),\n",
       "   (-1.9065191262702519, 'accepted'),\n",
       "   (-0.9532595631351259, 'acceptance'),\n",
       "   (-0.9532595631351259, 'accepting'),\n",
       "   (-0.9532595631351259, 'applauded'),\n",
       "   (-0.9532595631351259, 'foster')],\n",
       "  'REAL': [(0.9017821600417825, 'blow'),\n",
       "   (0.9017821600417825, 'case'),\n",
       "   (0.9017821600417825, 'creating'),\n",
       "   (0.9017821600417825, 'creation'),\n",
       "   (0.9017821600417825, 'dealt'),\n",
       "   (0.9017821600417825, 'happened'),\n",
       "   (0.9017821600417825, 'harmed'),\n",
       "   (0.9017821600417825, 'monopolies'),\n",
       "   (0.9767987058012866, 'block'),\n",
       "   (2.351396045837897, 'immigration')]},\n",
       " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "           multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "           verbose=0): {'FAKE': [(-0.3529489479943914, 'good'),\n",
       "   (-0.3455900464665536, 'banks'),\n",
       "   (-0.34443257454602866, 'taxes'),\n",
       "   (-0.32715797283245096, 'supports'),\n",
       "   (-0.32298253362819307, 'accepted'),\n",
       "   (-0.3032854970810706, 'people'),\n",
       "   (-0.30075851382497, 'fox'),\n",
       "   (-0.29806764273787556, 'time'),\n",
       "   (-0.2950283551437051, 'rest'),\n",
       "   (-0.28946355715899946, 'stated')],\n",
       "  'REAL': [(0.33366489011060696, 'costs'),\n",
       "   (0.3410972469154007, 'devos'),\n",
       "   (0.3440104489633723, 'billion'),\n",
       "   (0.35247847057972, 'tesla'),\n",
       "   (0.35414928730223216, 'tax'),\n",
       "   (0.35787998450955427, 'souq'),\n",
       "   (0.3895118209173843, 'pay'),\n",
       "   (0.4317301918208393, 'ford'),\n",
       "   (0.44032753970133126, 'amazon'),\n",
       "   (0.5861804687721129, 'said')]},\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "               power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=False): {'FAKE': [(-7.969427599491965,\n",
       "    'chronic'),\n",
       "   (-6.760452949955524, 'second'),\n",
       "   (-6.686297182424339, 'taxes'),\n",
       "   (-6.639041176421905, 'good'),\n",
       "   (-6.517957168656917, 'man'),\n",
       "   (-5.273890645386535, 'accepted'),\n",
       "   (-2.6369453226932675, 'acceptance'),\n",
       "   (-2.6369453226932675, 'accepting'),\n",
       "   (-2.6369453226932675, 'applauded'),\n",
       "   (-2.6369453226932675, 'foster')],\n",
       "  'REAL': [(2.6280879349995905, 'case'),\n",
       "   (2.6280879349995905, 'creating'),\n",
       "   (2.6280879349995905, 'creation'),\n",
       "   (2.6280879349995905, 'dealt'),\n",
       "   (2.6280879349995905, 'happened'),\n",
       "   (2.6280879349995905, 'harmed'),\n",
       "   (2.6280879349995905, 'monopolies'),\n",
       "   (2.902900338172482, 'block'),\n",
       "   (2.907248096929784, 'said'),\n",
       "   (6.951827252541858, 'immigration')]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is both a bit hard to read and compare. What I really want is to see these possibly with ranks and compare the tokens to one another. Let's transform the data to look better for what we are trying to measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparable_results = {'REAL': {}, 'FAKE': {}}\n",
    "for clf, data in results.items():\n",
    "    clf_name = clf.__class__.__name__\n",
    "    for label, features in data.items():\n",
    "        for rank, score_tuple in enumerate(features):\n",
    "            if score_tuple[1] in comparable_results[label]:\n",
    "                comparable_results[label][score_tuple[1]].append((rank + 1, clf_name))\n",
    "            else:\n",
    "                comparable_results[label][score_tuple[1]] = [(rank + 1, clf_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these are a bit easier to compare and read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100th': [(1, 'MultinomialNB'), (1, 'MultinomialNB')],\n",
       " '12th': [(2, 'MultinomialNB'), (2, 'MultinomialNB')],\n",
       " '16': [(3, 'MultinomialNB'), (3, 'MultinomialNB')],\n",
       " '1950s': [(4, 'MultinomialNB'), (4, 'MultinomialNB')],\n",
       " '1960s': [(5, 'MultinomialNB'), (5, 'MultinomialNB')],\n",
       " '1978': [(6, 'MultinomialNB'), (6, 'MultinomialNB')],\n",
       " '200': [(7, 'MultinomialNB'), (7, 'MultinomialNB')],\n",
       " '2007': [(8, 'MultinomialNB'), (8, 'MultinomialNB')],\n",
       " '2011': [(9, 'MultinomialNB'), (9, 'MultinomialNB')],\n",
       " '20m': [(10, 'MultinomialNB'), (10, 'MultinomialNB')],\n",
       " 'chronic': [(1, 'PassiveAggressiveClassifier'), (1, 'SGDClassifier')],\n",
       " 'taxes': [(2, 'PassiveAggressiveClassifier'),\n",
       "  (3, 'LinearSVC'),\n",
       "  (3, 'SGDClassifier')],\n",
       " 'second': [(3, 'PassiveAggressiveClassifier'), (2, 'SGDClassifier')],\n",
       " 'good': [(4, 'PassiveAggressiveClassifier'),\n",
       "  (1, 'LinearSVC'),\n",
       "  (4, 'SGDClassifier')],\n",
       " 'man': [(5, 'PassiveAggressiveClassifier'), (5, 'SGDClassifier')],\n",
       " 'accepted': [(6, 'PassiveAggressiveClassifier'),\n",
       "  (5, 'LinearSVC'),\n",
       "  (6, 'SGDClassifier')],\n",
       " 'acceptance': [(7, 'PassiveAggressiveClassifier'), (7, 'SGDClassifier')],\n",
       " 'accepting': [(8, 'PassiveAggressiveClassifier'), (8, 'SGDClassifier')],\n",
       " 'applauded': [(9, 'PassiveAggressiveClassifier'), (9, 'SGDClassifier')],\n",
       " 'foster': [(10, 'PassiveAggressiveClassifier'), (10, 'SGDClassifier')],\n",
       " 'banks': [(2, 'LinearSVC')],\n",
       " 'supports': [(4, 'LinearSVC')],\n",
       " 'people': [(6, 'LinearSVC')],\n",
       " 'fox': [(7, 'LinearSVC')],\n",
       " 'time': [(8, 'LinearSVC')],\n",
       " 'rest': [(9, 'LinearSVC')],\n",
       " 'stated': [(10, 'LinearSVC')]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparable_results['FAKE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I immediately noticed the multinomial models had picked up quite a bit of noise from the dataset. These models likely would have benefit from some preprocessing. I also noticed that *most* of the models had picked up what I would consider noise, such as `2016` and the words `print` and `share` (which are clearly scraping artifacts).\n",
    "\n",
    "Let's see if we can score the tokens by popularity and rank. I also wanted to add in a warning message in case I had overlap between my real and fake tokens. (This may be the case if you take a larger n-features from each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results = {}\n",
    "for label, features in comparable_results.items():\n",
    "    for feature, ranks in features.items():\n",
    "        if feature in agg_results:\n",
    "            print(\"WARNING! DUPLICATE LABEL!!! {}\".format(feature))\n",
    "        agg_results[feature] = {\n",
    "            'label': label,\n",
    "            'agg_rank': np.mean([r[0] for r in ranks]),\n",
    "            'count': len(ranks)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can then put this into a dataframe, for easier transformations and viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame(agg_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commission</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agg_rank count label\n",
       "president         1     1  REAL\n",
       "trump             2     1  REAL\n",
       "commission        3     1  REAL\n",
       "exchange          3     2  REAL\n",
       "stock             5     2  REAL"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate the top real and fake labels, I would advise to sort by count. Let's see my top 10 tokens for real and fake news ranked by the number of classifiers that used them as a top feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>9.75</td>\n",
       "      <td>4</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creating</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billion</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block</th>\n",
       "      <td>8.5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monopolies</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harmed</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happened</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dealt</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creation</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agg_rank count label\n",
       "said           9.75     4  REAL\n",
       "creating        2.5     2  REAL\n",
       "billion           2     2  REAL\n",
       "block           8.5     2  REAL\n",
       "monopolies      7.5     2  REAL\n",
       "harmed          6.5     2  REAL\n",
       "happened        5.5     2  REAL\n",
       "dealt           4.5     2  REAL\n",
       "creation        3.5     2  REAL\n",
       "case            1.5     2  REAL"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df[comparison_df['label'] == 'REAL'].sort_values('count', ascending=0).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxes</th>\n",
       "      <td>2.66667</td>\n",
       "      <td>3</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accepted</th>\n",
       "      <td>5.66667</td>\n",
       "      <td>3</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foster</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applauded</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accepting</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceptance</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12th</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agg_rank count label\n",
       "good              3     3  FAKE\n",
       "taxes       2.66667     3  FAKE\n",
       "accepted    5.66667     3  FAKE\n",
       "foster           10     2  FAKE\n",
       "applauded         9     2  FAKE\n",
       "accepting         8     2  FAKE\n",
       "acceptance        7     2  FAKE\n",
       "man               5     2  FAKE\n",
       "12th              2     2  FAKE\n",
       "second          2.5     2  FAKE"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df[comparison_df['label'] == 'FAKE'].sort_values('count', ascending=0).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "As expected, the bag-of-words and TF-IDF vectors didn't do much to determine meaningful features to classify fake or real news. As outlined in my DataCamp post, this problem is a lot harder than simple text classification.\n",
    "\n",
    "That said, I did learn a few things. Namely, that linear models handle noise in this case better than the Naive Bayes multinomial classifier did. Also, finding a good dataset that has been scraped from the web and tagged for this problem would likely be a great help, and worth more of my time than parameter tuning on a clearly noisy and error prone dataset.\n",
    "\n",
    "If you spend some time researching and find anything interesting, feel free to share your findings and notes in the comments or you can always reach out on Twitter (I'm [@kjam](https://twitter.com/kjam)).\n",
    "\n",
    "I hope you had some fun exploring a new NLP dataset with me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix A: Top features\n",
    "\n",
    "Once I realized the Naive Bayes classifiers had identified many noisy tokens in alphabetical order as top fake news classifiers, I decided to see just how many \"top features\" the model had. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (-9.946977983610656, '100th')\n"
     ]
    }
   ],
   "source": [
    "feature_names = count_vectorizer.get_feature_names()\n",
    "for idx, ftr_weight in enumerate(sorted(zip(mn_count_clf.coef_[0], feature_names))):\n",
    "    if ftr_weight[0] <= -16.067750538483136:\n",
    "        continue\n",
    "    print(idx, ftr_weight)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
