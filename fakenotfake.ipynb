{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Extra-Info\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['rank', 'clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Fake News Classifiers\n",
    "\n",
    "I wrote a longer explanation of the methodology and approach for detecting fake news using scikit-learn on DataCamp (and you can [find the notebook on my GitHub](https://github.com/kjam/random_hackery/blob/master/Attempting%20to%20detect%20fake%20news.ipynb)). I would start there if you are curious as to why I chose the data, what I learned about the models and so forth.\n",
    "\n",
    "In this notebook, I wanted to compare some of the features learned by each classifier to see if there was overlap or patterns in the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 4: expected 1 fields, saw 4\\nSkipping line 5: expected 1 fields, saw 2\\nSkipping line 6: expected 1 fields, saw 2\\nSkipping line 7: expected 1 fields, saw 3\\nSkipping line 8: expected 1 fields, saw 4\\nSkipping line 9: expected 1 fields, saw 7\\nSkipping line 10: expected 1 fields, saw 2\\nSkipping line 11: expected 1 fields, saw 7\\nSkipping line 12: expected 1 fields, saw 2\\nSkipping line 13: expected 1 fields, saw 9\\nSkipping line 16: expected 1 fields, saw 4\\nSkipping line 17: expected 1 fields, saw 2\\nSkipping line 19: expected 1 fields, saw 8\\nSkipping line 20: expected 1 fields, saw 2\\nSkipping line 21: expected 1 fields, saw 2\\nSkipping line 22: expected 1 fields, saw 9\\nSkipping line 23: expected 1 fields, saw 3\\nSkipping line 24: expected 1 fields, saw 3\\nSkipping line 25: expected 1 fields, saw 8\\nSkipping line 26: expected 1 fields, saw 5\\nSkipping line 27: expected 1 fields, saw 8\\nSkipping line 28: expected 1 fields, saw 3\\nSkipping line 29: expected 1 fields, saw 2\\nSkipping line 30: expected 1 fields, saw 6\\nSkipping line 31: expected 1 fields, saw 2\\nSkipping line 34: expected 1 fields, saw 4\\nSkipping line 35: expected 1 fields, saw 5\\nSkipping line 36: expected 1 fields, saw 4\\nSkipping line 38: expected 1 fields, saw 5\\nSkipping line 39: expected 1 fields, saw 2\\nSkipping line 40: expected 1 fields, saw 3\\nSkipping line 42: expected 1 fields, saw 6\\nSkipping line 43: expected 1 fields, saw 10\\nSkipping line 44: expected 1 fields, saw 5\\nSkipping line 45: expected 1 fields, saw 6\\nSkipping line 46: expected 1 fields, saw 5\\nSkipping line 47: expected 1 fields, saw 7\\nSkipping line 48: expected 1 fields, saw 2\\nSkipping line 49: expected 1 fields, saw 3\\nSkipping line 50: expected 1 fields, saw 7\\nSkipping line 51: expected 1 fields, saw 2\\nSkipping line 52: expected 1 fields, saw 11\\nSkipping line 54: expected 1 fields, saw 6\\nSkipping line 55: expected 1 fields, saw 5\\nSkipping line 56: expected 1 fields, saw 4\\nSkipping line 57: expected 1 fields, saw 3\\nSkipping line 58: expected 1 fields, saw 2\\nSkipping line 59: expected 1 fields, saw 3\\nSkipping line 60: expected 1 fields, saw 3\\nSkipping line 61: expected 1 fields, saw 3\\nSkipping line 62: expected 1 fields, saw 4\\nSkipping line 63: expected 1 fields, saw 23\\nSkipping line 64: expected 1 fields, saw 6\\nSkipping line 65: expected 1 fields, saw 6\\nSkipping line 66: expected 1 fields, saw 3\\nSkipping line 67: expected 1 fields, saw 2\\nSkipping line 68: expected 1 fields, saw 2\\nSkipping line 69: expected 1 fields, saw 3\\nSkipping line 71: expected 1 fields, saw 4\\nSkipping line 72: expected 1 fields, saw 6\\nSkipping line 73: expected 1 fields, saw 5\\nSkipping line 74: expected 1 fields, saw 11\\nSkipping line 75: expected 1 fields, saw 7\\nSkipping line 76: expected 1 fields, saw 2\\nSkipping line 77: expected 1 fields, saw 2\\nSkipping line 78: expected 1 fields, saw 10\\nSkipping line 79: expected 1 fields, saw 3\\nSkipping line 80: expected 1 fields, saw 7\\nSkipping line 81: expected 1 fields, saw 8\\nSkipping line 82: expected 1 fields, saw 7\\nSkipping line 83: expected 1 fields, saw 2\\nSkipping line 84: expected 1 fields, saw 3\\nSkipping line 85: expected 1 fields, saw 2\\nSkipping line 86: expected 1 fields, saw 9\\nSkipping line 87: expected 1 fields, saw 3\\nSkipping line 88: expected 1 fields, saw 3\\nSkipping line 89: expected 1 fields, saw 22\\nSkipping line 90: expected 1 fields, saw 10\\nSkipping line 91: expected 1 fields, saw 15\\nSkipping line 92: expected 1 fields, saw 2\\nSkipping line 93: expected 1 fields, saw 9\\nSkipping line 94: expected 1 fields, saw 5\\nSkipping line 95: expected 1 fields, saw 2\\nSkipping line 96: expected 1 fields, saw 2\\nSkipping line 97: expected 1 fields, saw 2\\nSkipping line 98: expected 1 fields, saw 8\\nSkipping line 99: expected 1 fields, saw 9\\nSkipping line 100: expected 1 fields, saw 4\\nSkipping line 101: expected 1 fields, saw 2\\nSkipping line 102: expected 1 fields, saw 4\\nSkipping line 103: expected 1 fields, saw 5\\nSkipping line 104: expected 1 fields, saw 2\\nSkipping line 105: expected 1 fields, saw 7\\nSkipping line 106: expected 1 fields, saw 4\\nSkipping line 107: expected 1 fields, saw 5\\nSkipping line 108: expected 1 fields, saw 3\\nSkipping line 109: expected 1 fields, saw 6\\nSkipping line 110: expected 1 fields, saw 4\\nSkipping line 114: expected 1 fields, saw 3\\nSkipping line 117: expected 1 fields, saw 3\\nSkipping line 133: expected 1 fields, saw 2\\nSkipping line 134: expected 1 fields, saw 3\\nSkipping line 140: expected 1 fields, saw 3\\nSkipping line 141: expected 1 fields, saw 2\\nSkipping line 146: expected 1 fields, saw 7\\nSkipping line 149: expected 1 fields, saw 2\\nSkipping line 151: expected 1 fields, saw 3\\nSkipping line 152: expected 1 fields, saw 2\\nSkipping line 154: expected 1 fields, saw 5\\nSkipping line 157: expected 1 fields, saw 5\\nSkipping line 158: expected 1 fields, saw 5\\nSkipping line 160: expected 1 fields, saw 3\\nSkipping line 163: expected 1 fields, saw 2\\nSkipping line 165: expected 1 fields, saw 5\\nSkipping line 166: expected 1 fields, saw 3\\nSkipping line 168: expected 1 fields, saw 5\\nSkipping line 171: expected 1 fields, saw 2\\nSkipping line 173: expected 1 fields, saw 2\\nSkipping line 174: expected 1 fields, saw 5\\nSkipping line 176: expected 1 fields, saw 3\\nSkipping line 179: expected 1 fields, saw 5\\nSkipping line 181: expected 1 fields, saw 4\\nSkipping line 182: expected 1 fields, saw 2\\nSkipping line 184: expected 1 fields, saw 2\\nSkipping line 185: expected 1 fields, saw 3\\nSkipping line 187: expected 1 fields, saw 6\\nSkipping line 190: expected 1 fields, saw 2\\nSkipping line 192: expected 1 fields, saw 5\\nSkipping line 197: expected 1 fields, saw 2\\nSkipping line 200: expected 1 fields, saw 2\\nSkipping line 201: expected 1 fields, saw 4\\nSkipping line 203: expected 1 fields, saw 2\\nSkipping line 206: expected 1 fields, saw 4\\nSkipping line 208: expected 1 fields, saw 8\\nSkipping line 209: expected 1 fields, saw 2\\nSkipping line 211: expected 1 fields, saw 3\\nSkipping line 212: expected 1 fields, saw 8\\nSkipping line 214: expected 1 fields, saw 6\\nSkipping line 215: expected 1 fields, saw 3\\nSkipping line 217: expected 1 fields, saw 5\\nSkipping line 218: expected 1 fields, saw 3\\nSkipping line 220: expected 1 fields, saw 6\\nSkipping line 223: expected 1 fields, saw 2\\nSkipping line 225: expected 1 fields, saw 3\\nSkipping line 226: expected 1 fields, saw 3\\nSkipping line 227: expected 1 fields, saw 3\\nSkipping line 230: expected 1 fields, saw 3\\nSkipping line 232: expected 1 fields, saw 2\\nSkipping line 234: expected 1 fields, saw 4\\nSkipping line 235: expected 1 fields, saw 2\\nSkipping line 237: expected 1 fields, saw 2\\nSkipping line 239: expected 1 fields, saw 4\\nSkipping line 242: expected 1 fields, saw 2\\nSkipping line 246: expected 1 fields, saw 2\\nSkipping line 247: expected 1 fields, saw 3\\nSkipping line 252: expected 1 fields, saw 3\\nSkipping line 256: expected 1 fields, saw 11\\nSkipping line 257: expected 1 fields, saw 3\\nSkipping line 259: expected 1 fields, saw 2\\nSkipping line 260: expected 1 fields, saw 5\\nSkipping line 262: expected 1 fields, saw 3\\nSkipping line 264: expected 1 fields, saw 2\\nSkipping line 265: expected 1 fields, saw 7\\nSkipping line 270: expected 1 fields, saw 4\\nSkipping line 279: expected 1 fields, saw 6\\nSkipping line 282: expected 1 fields, saw 3\\nSkipping line 285: expected 1 fields, saw 3\\nSkipping line 290: expected 1 fields, saw 2\\nSkipping line 294: expected 1 fields, saw 4\\nSkipping line 296: expected 1 fields, saw 8\\nSkipping line 297: expected 1 fields, saw 4\\nSkipping line 300: expected 1 fields, saw 3\\nSkipping line 304: expected 1 fields, saw 4\\nSkipping line 306: expected 1 fields, saw 3\\nSkipping line 308: expected 1 fields, saw 3\\nSkipping line 309: expected 1 fields, saw 2\\nSkipping line 311: expected 1 fields, saw 4\\nSkipping line 312: expected 1 fields, saw 2\\nSkipping line 315: expected 1 fields, saw 2\\nSkipping line 316: expected 1 fields, saw 3\\nSkipping line 318: expected 1 fields, saw 4\\nSkipping line 320: expected 1 fields, saw 3\\nSkipping line 321: expected 1 fields, saw 2\\nSkipping line 323: expected 1 fields, saw 2\\nSkipping line 324: expected 1 fields, saw 2\\nSkipping line 326: expected 1 fields, saw 4\\nSkipping line 329: expected 1 fields, saw 2\\nSkipping line 331: expected 1 fields, saw 2\\nSkipping line 333: expected 1 fields, saw 2\\nSkipping line 334: expected 1 fields, saw 2\\nSkipping line 336: expected 1 fields, saw 3\\nSkipping line 337: expected 1 fields, saw 3\\nSkipping line 338: expected 1 fields, saw 2\\nSkipping line 340: expected 1 fields, saw 5\\nSkipping line 341: expected 1 fields, saw 3\\nSkipping line 342: expected 1 fields, saw 3\\nSkipping line 344: expected 1 fields, saw 2\\nSkipping line 345: expected 1 fields, saw 2\\nSkipping line 346: expected 1 fields, saw 2\\nSkipping line 348: expected 1 fields, saw 3\\nSkipping line 350: expected 1 fields, saw 6\\nSkipping line 352: expected 1 fields, saw 5\\nSkipping line 354: expected 1 fields, saw 3\\nSkipping line 355: expected 1 fields, saw 2\\nSkipping line 357: expected 1 fields, saw 6\\nSkipping line 360: expected 1 fields, saw 3\\nSkipping line 362: expected 1 fields, saw 2\\nSkipping line 363: expected 1 fields, saw 3\\nSkipping line 365: expected 1 fields, saw 3\\nSkipping line 367: expected 1 fields, saw 6\\nSkipping line 368: expected 1 fields, saw 5\\nSkipping line 370: expected 1 fields, saw 4\\nSkipping line 372: expected 1 fields, saw 7\\nSkipping line 373: expected 1 fields, saw 3\\nSkipping line 375: expected 1 fields, saw 5\\nSkipping line 379: expected 1 fields, saw 4\\nSkipping line 381: expected 1 fields, saw 2\\nSkipping line 383: expected 1 fields, saw 3\\nSkipping line 384: expected 1 fields, saw 2\\nSkipping line 386: expected 1 fields, saw 2\\nSkipping line 387: expected 1 fields, saw 2\\nSkipping line 389: expected 1 fields, saw 8\\nSkipping line 392: expected 1 fields, saw 3\\nSkipping line 393: expected 1 fields, saw 2\\nSkipping line 395: expected 1 fields, saw 6\\nSkipping line 398: expected 1 fields, saw 3\\nSkipping line 400: expected 1 fields, saw 3\\nSkipping line 402: expected 1 fields, saw 4\\nSkipping line 403: expected 1 fields, saw 2\\nSkipping line 405: expected 1 fields, saw 3\\nSkipping line 407: expected 1 fields, saw 2\\nSkipping line 408: expected 1 fields, saw 4\\nSkipping line 410: expected 1 fields, saw 4\\nSkipping line 412: expected 1 fields, saw 4\\nSkipping line 415: expected 1 fields, saw 2\\nSkipping line 417: expected 1 fields, saw 3\\nSkipping line 420: expected 1 fields, saw 4\\nSkipping line 422: expected 1 fields, saw 2\\nSkipping line 425: expected 1 fields, saw 4\\nSkipping line 426: expected 1 fields, saw 3\\nSkipping line 428: expected 1 fields, saw 2\\nSkipping line 430: expected 1 fields, saw 5\\nSkipping line 431: expected 1 fields, saw 4\\nSkipping line 433: expected 1 fields, saw 8\\nSkipping line 434: expected 1 fields, saw 2\\nSkipping line 436: expected 1 fields, saw 4\\nSkipping line 437: expected 1 fields, saw 3\\nSkipping line 439: expected 1 fields, saw 4\\nSkipping line 441: expected 1 fields, saw 2\\nSkipping line 449: expected 1 fields, saw 4\\nSkipping line 450: expected 1 fields, saw 2\\nSkipping line 474: expected 1 fields, saw 2\\nSkipping line 476: expected 1 fields, saw 5\\nSkipping line 478: expected 1 fields, saw 3\\nSkipping line 479: expected 1 fields, saw 3\\nSkipping line 481: expected 1 fields, saw 3\\nSkipping line 484: expected 1 fields, saw 2\\nSkipping line 488: expected 1 fields, saw 2\\nSkipping line 490: expected 1 fields, saw 2\\nSkipping line 491: expected 1 fields, saw 2\\nSkipping line 493: expected 1 fields, saw 4\\nSkipping line 496: expected 1 fields, saw 3\\nSkipping line 497: expected 1 fields, saw 2\\nSkipping line 498: expected 1 fields, saw 2\\nSkipping line 500: expected 1 fields, saw 3\\nSkipping line 501: expected 1 fields, saw 2\\nSkipping line 503: expected 1 fields, saw 3\\nSkipping line 505: expected 1 fields, saw 6\\nSkipping line 506: expected 1 fields, saw 3\\nSkipping line 508: expected 1 fields, saw 4\\nSkipping line 509: expected 1 fields, saw 3\\nSkipping line 511: expected 1 fields, saw 2\\nSkipping line 514: expected 1 fields, saw 2\\nSkipping line 516: expected 1 fields, saw 9\\nSkipping line 517: expected 1 fields, saw 3\\nSkipping line 519: expected 1 fields, saw 4\\nSkipping line 520: expected 1 fields, saw 3\\nSkipping line 522: expected 1 fields, saw 4\\nSkipping line 524: expected 1 fields, saw 2\\nSkipping line 525: expected 1 fields, saw 2\\nSkipping line 527: expected 1 fields, saw 4\\nSkipping line 530: expected 1 fields, saw 4\\nSkipping line 532: expected 1 fields, saw 3\\nSkipping line 535: expected 1 fields, saw 5\\nSkipping line 536: expected 1 fields, saw 2\\nSkipping line 538: expected 1 fields, saw 2\\nSkipping line 540: expected 1 fields, saw 6\\nSkipping line 543: expected 1 fields, saw 9\\nSkipping line 544: expected 1 fields, saw 2\\nSkipping line 546: expected 1 fields, saw 3\\nSkipping line 548: expected 1 fields, saw 3\\nSkipping line 549: expected 1 fields, saw 2\\nSkipping line 551: expected 1 fields, saw 4\\nSkipping line 553: expected 1 fields, saw 5\\nSkipping line 554: expected 1 fields, saw 2\\nSkipping line 555: expected 1 fields, saw 2\\nSkipping line 556: expected 1 fields, saw 5\\nSkipping line 557: expected 1 fields, saw 2\\nSkipping line 558: expected 1 fields, saw 3\\nSkipping line 559: expected 1 fields, saw 2\\nSkipping line 561: expected 1 fields, saw 5\\nSkipping line 562: expected 1 fields, saw 2\\nSkipping line 565: expected 1 fields, saw 3\\nSkipping line 569: expected 1 fields, saw 2\\nSkipping line 572: expected 1 fields, saw 8\\nSkipping line 575: expected 1 fields, saw 3\\nSkipping line 577: expected 1 fields, saw 4\\nSkipping line 578: expected 1 fields, saw 2\\nSkipping line 579: expected 1 fields, saw 2\\nSkipping line 582: expected 1 fields, saw 2\\nSkipping line 584: expected 1 fields, saw 2\\nSkipping line 586: expected 1 fields, saw 3\\nSkipping line 587: expected 1 fields, saw 5\\nSkipping line 589: expected 1 fields, saw 6\\nSkipping line 590: expected 1 fields, saw 6\\nSkipping line 592: expected 1 fields, saw 3\\nSkipping line 593: expected 1 fields, saw 2\\nSkipping line 595: expected 1 fields, saw 3\\nSkipping line 597: expected 1 fields, saw 4\\nSkipping line 598: expected 1 fields, saw 2\\nSkipping line 600: expected 1 fields, saw 5\\nSkipping line 602: expected 1 fields, saw 4\\nSkipping line 603: expected 1 fields, saw 2\\nSkipping line 605: expected 1 fields, saw 4\\nSkipping line 607: expected 1 fields, saw 4\\nSkipping line 608: expected 1 fields, saw 7\\nSkipping line 609: expected 1 fields, saw 6\\nSkipping line 611: expected 1 fields, saw 4\\nSkipping line 612: expected 1 fields, saw 2\\nSkipping line 613: expected 1 fields, saw 5\\nSkipping line 614: expected 1 fields, saw 5\\nSkipping line 615: expected 1 fields, saw 4\\nSkipping line 616: expected 1 fields, saw 5\\nSkipping line 617: expected 1 fields, saw 6\\nSkipping line 618: expected 1 fields, saw 9\\nSkipping line 620: expected 1 fields, saw 17\\nSkipping line 622: expected 1 fields, saw 4\\nSkipping line 623: expected 1 fields, saw 4\\nSkipping line 624: expected 1 fields, saw 4\\nSkipping line 625: expected 1 fields, saw 2\\nSkipping line 627: expected 1 fields, saw 2\\nSkipping line 628: expected 1 fields, saw 2\\nSkipping line 630: expected 1 fields, saw 12\\nSkipping line 631: expected 1 fields, saw 7\\nSkipping line 632: expected 1 fields, saw 3\\nSkipping line 633: expected 1 fields, saw 4\\nSkipping line 634: expected 1 fields, saw 4\\nSkipping line 635: expected 1 fields, saw 13\\nSkipping line 637: expected 1 fields, saw 9\\nSkipping line 638: expected 1 fields, saw 3\\nSkipping line 639: expected 1 fields, saw 6\\nSkipping line 640: expected 1 fields, saw 2\\nSkipping line 641: expected 1 fields, saw 5\\nSkipping line 642: expected 1 fields, saw 3\\nSkipping line 643: expected 1 fields, saw 6\\nSkipping line 644: expected 1 fields, saw 7\\nSkipping line 646: expected 1 fields, saw 9\\nSkipping line 647: expected 1 fields, saw 12\\nSkipping line 648: expected 1 fields, saw 3\\nSkipping line 649: expected 1 fields, saw 3\\nSkipping line 650: expected 1 fields, saw 2\\nSkipping line 651: expected 1 fields, saw 4\\nSkipping line 652: expected 1 fields, saw 4\\nSkipping line 653: expected 1 fields, saw 2\\nSkipping line 654: expected 1 fields, saw 3\\nSkipping line 655: expected 1 fields, saw 12\\nSkipping line 656: expected 1 fields, saw 6\\nSkipping line 657: expected 1 fields, saw 5\\nSkipping line 658: expected 1 fields, saw 5\\nSkipping line 660: expected 1 fields, saw 8\\nSkipping line 663: expected 1 fields, saw 6\\nSkipping line 664: expected 1 fields, saw 4\\nSkipping line 666: expected 1 fields, saw 7\\nSkipping line 668: expected 1 fields, saw 5\\nSkipping line 670: expected 1 fields, saw 3\\nSkipping line 672: expected 1 fields, saw 5\\nSkipping line 678: expected 1 fields, saw 7\\nSkipping line 682: expected 1 fields, saw 4\\nSkipping line 698: expected 1 fields, saw 2\\nSkipping line 706: expected 1 fields, saw 3\\nSkipping line 708: expected 1 fields, saw 3\\nSkipping line 721: expected 1 fields, saw 6\\n'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('corpusTestAndTrain1.csv',encoding='latin-1', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-70dc24e0c53c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.25, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models\n",
    "\n",
    "Now I have my vectors and I can create my different classifiers. In my post I noted that there is definitely noise in the dataset, so we should expect to see that reflected in our features. Normally, I would spend some time cleaning the data, but this was a small proof of concept and investigation. I hoped merely that at least one model would be able to correct for the noise.\n",
    "\n",
    "I will compare the following models (and training data):\n",
    "\n",
    "- multinomialNB with counts (`sgd_count_clf`)\n",
    "- multinomialNB with tf-idf (`mn_tfidf_clf`)\n",
    "- passive aggressive with tf-idf (`pa_tfidf_clf`)\n",
    "- linear svc with tf-idf (`svc_tfidf_clf`)\n",
    "- linear sgd with tf-idf (`sgd_tfidf_clf`)\n",
    "\n",
    "For speed and clarity, I am primarily not doing parameter tuning, although this could be added as a step (perhaps in a scikit-learn Pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_count_clf = MultinomialNB(alpha=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_count_clf.fit(count_train, y_train)\n",
    "pred = mn_count_clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_tfidf_clf = MultinomialNB(alpha=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = mn_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_tfidf_clf = PassiveAggressiveClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = pa_tfidf_clf.predict(tfidf_test)\n",
    "score1 = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tfidf_clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = svc_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tfidf_clf = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = sgd_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classificationreport\")\n",
    "sgd_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = sgd_tfidf_clf.predict(tfidf_test)\n",
    "\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(y_test)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tfidf_clf.decision_function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_count_clf.predict_proba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0).clf()\n",
    "\n",
    "for model, name in [ (mn_count_clf, 'multinomial nb count'),\n",
    "                     (mn_tfidf_clf, 'multinomial nb tfidf'),\n",
    "                     (pa_tfidf_clf, 'passive aggressive'),\n",
    "                     (svc_tfidf_clf, 'svc'),\n",
    "                     (sgd_tfidf_clf, 'sgd')]:\n",
    "    if 'count' in name:\n",
    "        pred = model.predict_proba(count_test)[:,1]\n",
    "    elif 'multinomial' in name:\n",
    "        pred = model.predict_proba(tfidf_test)[:,1]\n",
    "    else: \n",
    "        pred = model.decision_function(tfidf_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test.values, pred, pos_label='REAL')\n",
    "    plt.plot(fpr,tpr,label=\"{}\".format(name))\n",
    "\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introspecting models\n",
    "\n",
    "My main goal for this notebook is not to compare accuracy, but to compare features learned. To do so, we can use the method shown in this [very useful StackOverflow answer](https://stackoverflow.com/a/26980472) to show significant features in a binary classifier. I will use a modified version to return top features for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=100):\n",
    "    \"\"\"\n",
    "    See: https://stackoverflow.com/a/26980472\n",
    "    \n",
    "    Identify most important features if given a vectorizer and binary classifier. Set n to the number\n",
    "    of weighted features you would like to show. (Note: current implementation merely prints and does not \n",
    "    return top classes.)\n",
    "    \n",
    "    Modified by @kjam to support a dict return.\n",
    "    \"\"\"\n",
    "\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    return {class_labels[0]: topn_class1,\n",
    "            class_labels[1]: topn_class2\n",
    "    }\n",
    "\n",
    "\n",
    "most_informative_feature_for_binary_classification(tfidf_vectorizer, pa_tfidf_clf, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [(mn_count_clf, count_vectorizer),\n",
    "               (mn_tfidf_clf, tfidf_vectorizer),\n",
    "               (pa_tfidf_clf, tfidf_vectorizer),\n",
    "               (svc_tfidf_clf, tfidf_vectorizer),\n",
    "               (sgd_tfidf_clf, tfidf_vectorizer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for clf, vct in classifiers:\n",
    "    results[clf] = most_informative_feature_for_binary_classification(vct, clf, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is both a bit hard to read and compare. What I really want is to see these possibly with ranks and compare the tokens to one another. Let's transform the data to look better for what we are trying to measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparable_results = {'REAL': {}, 'FAKE': {}}\n",
    "for clf, data in results.items():\n",
    "    clf_name = clf.__class__.__name__\n",
    "    for label, features in data.items():\n",
    "        for rank, score_tuple in enumerate(features):\n",
    "            if score_tuple[1] in comparable_results[label]:\n",
    "                comparable_results[label][score_tuple[1]].append((rank + 1, clf_name))\n",
    "            else:\n",
    "                comparable_results[label][score_tuple[1]] = [(rank + 1, clf_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these are a bit easier to compare and read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparable_results['FAKE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I immediately noticed the multinomial models had picked up quite a bit of noise from the dataset. These models likely would have benefit from some preprocessing. I also noticed that *most* of the models had picked up what I would consider noise, such as `2016` and the words `print` and `share` (which are clearly scraping artifacts).\n",
    "\n",
    "Let's see if we can score the tokens by popularity and rank. I also wanted to add in a warning message in case I had overlap between my real and fake tokens. (This may be the case if you take a larger n-features from each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results = {}\n",
    "for label, features in comparable_results.items():\n",
    "    for feature, ranks in features.items():\n",
    "        if feature in agg_results:\n",
    "            print(\"WARNING! DUPLICATE LABEL!!! {}\".format(feature))\n",
    "        agg_results[feature] = {\n",
    "            'label': label,\n",
    "            'agg_rank': np.mean([r[0] for r in ranks]),\n",
    "            'count': len(ranks)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can then put this into a dataframe, for easier transformations and viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame(agg_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate the top real and fake labels, I would advise to sort by count. Let's see my top 10 tokens for real and fake news ranked by the number of classifiers that used them as a top feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['label'] == 'REAL'].sort_values('count', ascending=0).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['label'] == 'FAKE'].sort_values('count', ascending=0).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "As expected, the bag-of-words and TF-IDF vectors didn't do much to determine meaningful features to classify fake or real news. As outlined in my DataCamp post, this problem is a lot harder than simple text classification.\n",
    "\n",
    "That said, I did learn a few things. Namely, that linear models handle noise in this case better than the Naive Bayes multinomial classifier did. Also, finding a good dataset that has been scraped from the web and tagged for this problem would likely be a great help, and worth more of my time than parameter tuning on a clearly noisy and error prone dataset.\n",
    "\n",
    "If you spend some time researching and find anything interesting, feel free to share your findings and notes in the comments or you can always reach out on Twitter (I'm [@kjam](https://twitter.com/kjam)).\n",
    "\n",
    "I hope you had some fun exploring a new NLP dataset with me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix A: Top features\n",
    "\n",
    "Once I realized the Naive Bayes classifiers had identified many noisy tokens in alphabetical order as top fake news classifiers, I decided to see just how many \"top features\" the model had. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
